{"id":"fef79c5927f14b28965e8518b8e5d030","object":"chat.completion","created":1747658237,"model":"codestral-latest","choices":[{"index":0,"message":{"role":"assistant","tool_calls":null,"content":"Below is a precise Python code using PyTorch to train a CNN with the specified configuration. The code includes comments, uses CUDA if available, and ensures the tensor dimensions are calculated correctly after each convolutional and pooling layer.\n\n```python\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\n\n# Set environment variable to avoid duplicate library issues\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n\n# Check if CUDA is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Define the dataset directories\ntrain_dir = 'F:/source/repos/datas/images 3 classes/mnist_dataset/train'\ntest_dir = 'F:/source/repos/datas/images 3 classes/mnist_dataset/test'\n\n# Define transformations for the training and testing sets\ntransform = transforms.Compose([\n    transforms.Resize((28, 28)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# Load the datasets\ntrain_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\ntest_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)\n\n# Define the CNN model\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n        self.pool5 = nn.MaxPool2d(kernel_size=1, stride=1, padding=0)\n        self.conv6 = nn.Conv2d(256, 10, kernel_size=1, stride=1, padding=0)\n\n        # Calculate the dimensions for the dense layers\n        self.fc1 = nn.Linear(self.convs(torch.randn(1, 3, 28, 28)).numel(), 20)\n        self.fc2 = nn.Linear(20, 10)\n\n    def convs(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = self.pool3(F.relu(self.conv3(x)))\n        x = self.pool4(F.relu(self.conv4(x)))\n        x = self.pool5(F.relu(self.conv5(x)))\n        x = F.relu(self.conv6(x))\n        return x\n\n    def forward(self, x):\n        x = self.convs(x)\n        x = x.view(x.size(0), -1)  # Flatten the tensor\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\n# Initialize the model, loss function, and optimizer\nmodel = CNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training the model\nnum_epochs = 50\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    train_loss = running_loss / len(train_loader)\n    train_accuracy = correct / total\n    train_losses.append(train_loss)\n    train_accuracies.append(train_accuracy)\n\n    # Validation\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    val_loss /= len(test_loader)\n    val_accuracy = correct / total\n    val_losses.append(val_loss)\n    val_accuracies.append(val_accuracy)\n\n    print(f'Epoch [{epoch+1}/{num_epochs}], '\n          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n\n# Save the trained model\nmodel_path = 'F:/source/repos/datas/images 3 classes/model_cnn.pth'\ntorch.save(model.state_dict(), model_path)\n\n# Plot the training and validation loss and accuracy curves\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Loss Curves')\n\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label='Train Accuracy')\nplt.plot(val_accuracies, label='Val Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Accuracy Curves')\n\nplt.show()\n```\n\nThis code defines a CNN model, trains it on the specified dataset, and saves the trained model. It also plots the training and validation loss and accuracy curves. Ensure that the dataset directory structure matches the specified format."},"finish_reason":"stop"}],"usage":{"prompt_tokens":651,"total_tokens":2208,"completion_tokens":1557}}